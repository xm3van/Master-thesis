{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "colab": {
      "name": "Hyperparameter tuning VD-VAE.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XzMmWMUEeEhG"
      },
      "source": [
        "Choice VD-VAE\n",
        "\n",
        "- Hyperparameter tuning: \n",
        "> - Complexity of Architecture [Default, Reasoned custom one, One VD-VAE from Child 2021] \n",
        "> - Window Size [32, 64, 128]\n",
        "> - Feature encoding RP, MTF, GADF, GASF  [GASF] \n",
        "> - Optimizer [DEFAULT] \n",
        "> - Loss Function [DEFAULT]\n",
        "> - n_epochs=3 [50]\n",
        "> - batch_size=256 [128, 64, 32]\n",
        "\n",
        "\n",
        "\n",
        "Action plan:\n",
        "- Find model with best setting on AMZN dataset \n",
        "- Iterate through all data sets\n",
        "\n",
        "- Hyperparameter round 1: \n",
        "> - Complexity of Architecture [Default, Reasoned custom one, One VD-VAE from Child 2021] \n",
        "> - Window Size [64, 128, 256]\n",
        "> - Feature encoding RP, MTF, GADF, GASF  [GASF] \n",
        "> - Optimizer [DEFAULT] \n",
        "> - Loss Function [DEFAULT]\n",
        "> - n_epochs=5 [5]\n",
        "> - batch_size=256 [256]\n",
        "> - only on AMZN\n",
        "\n",
        "\n",
        "- Hyperparameter round 2: \n",
        "> - Complexity of Architecture [Default, Reasoned custom one, One VD-VAE from Child 2021] \n",
        "> - Window Size [128]\n",
        "> - Feature encoding RP, MTF, GADF, GASF  [GASF] \n",
        "> - Optimizer [DEFAULT] \n",
        "> - Loss Function [DEFAULT]\n",
        "> - n_epochs=3 [50]\n",
        "> - batch_size=256 [64]\n",
        "\n",
        "Goal ==> build complexity of model architecture \n"
      ],
      "id": "XzMmWMUEeEhG"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a40527be"
      },
      "source": [
        "# VD-VAE"
      ],
      "id": "a40527be"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e3b1d347"
      },
      "source": [
        "# Section 0 - Set-up "
      ],
      "id": "e3b1d347"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i9gns559WJF9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c70768c-cb3f-4e2c-9081-a4dc72a0a830"
      },
      "source": [
        "pip install pyts"
      ],
      "id": "i9gns559WJF9",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pyts\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b6/2b/1a62c0d32b40ee85daa8f6a6160828537b3d846c9fe93253b38846c6ec1f/pyts-0.11.0-py3-none-any.whl (2.5MB)\n",
            "\u001b[K     |████████████████████████████████| 2.5MB 10.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: joblib>=0.12 in /usr/local/lib/python3.7/dist-packages (from pyts) (1.0.1)\n",
            "Requirement already satisfied: scipy>=1.3.0 in /usr/local/lib/python3.7/dist-packages (from pyts) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.17.5 in /usr/local/lib/python3.7/dist-packages (from pyts) (1.19.5)\n",
            "Requirement already satisfied: scikit-learn>=0.22.1 in /usr/local/lib/python3.7/dist-packages (from pyts) (0.22.2.post1)\n",
            "Requirement already satisfied: numba>=0.48.0 in /usr/local/lib/python3.7/dist-packages (from pyts) (0.51.2)\n",
            "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba>=0.48.0->pyts) (0.34.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba>=0.48.0->pyts) (56.1.0)\n",
            "Installing collected packages: pyts\n",
            "Successfully installed pyts-0.11.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FdI4PC0O-qvc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "62a0f055-853d-4227-8ee0-3cc56495a325"
      },
      "source": [
        "! pip install kornia\n",
        "!git clone https://www.github.com/EugenHotaj/pytorch-generative pytorch_generative_all \n",
        "!mv pytorch_generative_all/pytorch_generative pytorch_generative"
      ],
      "id": "FdI4PC0O-qvc",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting kornia\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/da/f4/a47657770c423ad1e1d41295fd030442cc7e4987fe05936b0423b9d982d5/kornia-0.5.2-py2.py3-none-any.whl (279kB)\n",
            "\r\u001b[K     |█▏                              | 10kB 14.4MB/s eta 0:00:01\r\u001b[K     |██▍                             | 20kB 17.5MB/s eta 0:00:01\r\u001b[K     |███▌                            | 30kB 21.5MB/s eta 0:00:01\r\u001b[K     |████▊                           | 40kB 21.6MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 51kB 11.9MB/s eta 0:00:01\r\u001b[K     |███████                         | 61kB 10.4MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 71kB 11.4MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 81kB 11.8MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 92kB 12.5MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 102kB 11.4MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 112kB 11.4MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 122kB 11.4MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 133kB 11.4MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 143kB 11.4MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 153kB 11.4MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 163kB 11.4MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 174kB 11.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 184kB 11.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 194kB 11.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 204kB 11.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 215kB 11.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 225kB 11.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 235kB 11.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 245kB 11.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 256kB 11.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 266kB 11.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 276kB 11.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 286kB 11.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from kornia) (1.19.5)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from kornia) (1.8.1+cu101)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.6.0->kornia) (3.7.4.3)\n",
            "Installing collected packages: kornia\n",
            "Successfully installed kornia-0.5.2\n",
            "Cloning into 'pytorch_generative_all'...\n",
            "warning: redirecting to https://github.com/EugenHotaj/pytorch-generative.git/\n",
            "remote: Enumerating objects: 1183, done.\u001b[K\n",
            "remote: Counting objects: 100% (428/428), done.\u001b[K\n",
            "remote: Compressing objects: 100% (330/330), done.\u001b[K\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "268ef53d"
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torch.optim as optim\n",
        "import argparse\n",
        "import matplotlib\n",
        "import torch.nn as nn\n",
        "import matplotlib.pyplot as plt\n",
        "import torchvision.transforms as transforms\n",
        "from torch.nn import functional as F\n",
        "import tensorflow as tf\n",
        "from tqdm import tqdm\n",
        "matplotlib.style.use('ggplot')\n",
        "\n",
        "# Get things ready\n",
        "import pytorch_generative as pg\n",
        "#import pytorch_generative.models.vd_vae as vd_vae\n",
        "\n",
        "# import function \n",
        "import numpy as np \n",
        "from os.path import join\n",
        "from os import getcwd\n",
        "import pandas as pd\n",
        "\n",
        "from google.colab import drive\n",
        "import sys\n",
        "\n",
        "#import functions\n",
        "import pyts\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.axes_grid1 import ImageGrid\n",
        "from pyts.image import GramianAngularField\n",
        "from pyts.image import RecurrencePlot\n",
        "from pyts.image import MarkovTransitionField\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import gc\n",
        "\n",
        "from sklearn.metrics import f1_score, confusion_matrix\n",
        "\n"
      ],
      "id": "268ef53d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oO55-IklVsKR"
      },
      "source": [
        "4/1AY0e-g59WMj9fEsVy1RgqitDvG4-Rorn1m4KQYdP6XFNIUvBwZAC_36hh-4\n",
        "## set-up path\n",
        "drive.mount('/content/drive')\n",
        "sys.path.append('/content/drive/My Drive/Master in Data Science and Society/Master Thesis/Code & Data Set')\n",
        "path = '/content/drive/My Drive/Master in Data Science and Society/Master Thesis/Code & Data Set/labels/realAdExchange/twitterADVec_exchange-4_cpm_results.csv'\n",
        "\n",
        "## load data\n",
        "df = pd.read_csv(path)\n",
        "ts = np.array(df['value'])"
      ],
      "id": "oO55-IklVsKR",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ca2e989"
      },
      "source": [
        "# Section 1 - Pre-processing\n"
      ],
      "id": "1ca2e989"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u8XGq-psECGO"
      },
      "source": [
        "## Functions"
      ],
      "id": "u8XGq-psECGO"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "330f061f"
      },
      "source": [
        "# functions \n",
        "def preprocess_images(images):\n",
        "  images = images.reshape((images.shape[0], 1, window_size,window_size))\n",
        "  return images\n",
        "\n",
        "def rolling_window(ts, window):\n",
        "  \"\"\"  \n",
        "  Segreates times series to windows of size S \n",
        "  in rolling fashion \n",
        "\n",
        "  For example: \n",
        "  window0 = [x0, x1, x2]\n",
        "  window1 = [x1, x2, x3]\n",
        "  ...\n",
        "  \n",
        "  Arguments: \n",
        "  > ts = univariate time series \n",
        "  > window_size = int length of window\n",
        "  \"\"\"\n",
        "  shape = ts.shape[:-1] + (ts.shape[-1] - window + 1, window)\n",
        "  strides = ts.strides + (ts.strides[-1],)\n",
        "  return np.lib.stride_tricks.as_strided(ts, shape=shape, strides=strides)\n",
        "  \n",
        "      # \"\"\"References\"\"\"\n",
        "      # [1]https://rigtorp.se/2011/01/01/rolling-statistics-numpy.html\n",
        "      # [2]https://stackoverflow.com/questions/27852343/split-python-sequence-time-series-array-into-subsequences-with-overlap\n"
      ],
      "id": "330f061f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5_NiukzvEHV5"
      },
      "source": [
        "## Dataset prep"
      ],
      "id": "5_NiukzvEHV5"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rx9ifB06ZMGG"
      },
      "source": [
        "#Prep Dataset List \n",
        "dataset_loader_list = {}\n",
        "\n",
        "#set batch size\n",
        "batch_size = 64\n",
        "\n",
        "# prep\n",
        "for window_size in [64]: #, 128]: \n",
        "\n",
        "  #set up model\n",
        "  gasf = GramianAngularField(image_size=window_size, method='summation')# , sample_range=(0,1))\n",
        "  \n",
        "  #GAF\n",
        "  ts_windows = rolling_window(ts, window_size)\n",
        "  \n",
        "  \n",
        "  ## set up list storing img of ts window\n",
        "  ts_windows_img = []\n",
        "\n",
        "  for ts_window in ts_windows:\n",
        "\n",
        "    ### GASF Transform\n",
        "    X_gasf = gasf.fit_transform(ts_window.reshape(1,-1))\n",
        "\n",
        "    ts_windows_img.append(X_gasf[0])\n",
        "\n",
        "  # convert to tensor\n",
        "  tensor_img = torch.Tensor(ts_windows_img)\n",
        "\n",
        "  # Data loader set up \n",
        "  X_train, X_val, _, _ = train_test_split(tensor_img, \n",
        "                                          tensor_img,\n",
        "                                          test_size=0.1, \n",
        "                                          random_state=42)\n",
        "\n",
        "  ## Dataset GAF\n",
        "  data_loader_train_GAF = torch.utils.data.DataLoader(preprocess_images(X_train),\n",
        "                                            batch_size=batch_size,\n",
        "                                            shuffle=False)\n",
        "\n",
        "  data_loader_val_GAF = torch.utils.data.DataLoader(preprocess_images(X_val),\n",
        "                                            batch_size=batch_size ,\n",
        "                                            shuffle=False)\n",
        "\n",
        "  data_loader_test_GAF = torch.utils.data.DataLoader(preprocess_images(tensor_img),\n",
        "                                            batch_size=batch_size ,\n",
        "                                            shuffle=False)\n",
        "  \n",
        "  dataset_loader_list[f'GAF{str(window_size)}'] = (window_size,\n",
        "                                                   data_loader_train_GAF,\n",
        "                                                   data_loader_val_GAF,\n",
        "                                                   data_loader_test_GAF)\n",
        "\n",
        "\n"
      ],
      "id": "rx9ifB06ZMGG",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3f6a40d6"
      },
      "source": [
        "# Train VAE "
      ],
      "id": "3f6a40d6"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fOSM9S6RgK_-"
      },
      "source": [
        "import pytorch_generative.models.vae.vd_vae as vd_vae\n",
        "# Hyperparameter - unchanged for now\n",
        "\n",
        "## Loss, Optimizer, sample \n",
        "\n",
        "def loss_fn(x, _, preds):\n",
        "        preds, kl_div = preds\n",
        "        recon_loss = F.mse_loss(preds, x, reduction=\"none\")\n",
        "        recon_loss = recon_loss.sum(dim=(1, 2, 3))\n",
        "        elbo = recon_loss + kl_div\n",
        "        log.append((recon_loss.mean(),kl_div.mean(),elbo.mean()))\n",
        "\n",
        "        return {\n",
        "            \"recon_loss\": recon_loss.mean(),\n",
        "            \"kl_div\": kl_div.mean(),\n",
        "            \"loss\": elbo.mean(),\n",
        "        }\n",
        "\n",
        "def sample_fn(model):\n",
        "        sample = torch.sigmoid(model.sample(n_samples=16))\n",
        "        return torch.where(\n",
        "            sample < 0.5, torch.zeros_like(sample), torch.ones_like(sample)\n",
        "        )\n"
      ],
      "id": "fOSM9S6RgK_-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cd8d2b77"
      },
      "source": [
        "eval_score = {}\n",
        "#n_epochs=5 #seems to overfit after 5 epochs\n",
        "log_dir=\"/tmp/run\"\n",
        "n_gpus=1\n",
        "device_id=0\n",
        "debug_loader=None\n",
        "log=[]\n",
        "\n",
        "#     ws, train, val, test = dataset_loader_list[f'{ds}'] \n",
        "ws, train, val, test = dataset_loader_list[f'GAF64'] \n",
        "\n",
        "#for ds_key in dataset_loader_list.keys():\n",
        "    #print(f'Dataset:{ds_key}')\n",
        "    #ws, train, val, test = dataset_loader_list[ds_key]\n",
        "\n",
        "lc, hc, bc, stack, lr, n_epochs\n",
        "for lc in [2,4]:\n",
        "  \n",
        "    for hc, bc in [(32,8),(64,16),(128,32)]: #[(32,8),(64,16),(128,32)]:\n",
        "      \n",
        "      for stack in [(1,1,1,1,1,1)], (7,7,7,7,7,4), (4,4,4,4,4,2)]:\n",
        "\n",
        "        for lr in [0.00001]:\n",
        "\n",
        "          for n_epochs in [5,10]:\n",
        "            \n",
        "          \n",
        "\n",
        "            stack_configs = [\n",
        "              vd_vae.StackConfig(n_encoder_blocks=stack[5], n_decoder_blocks=stack[5]),\n",
        "              vd_vae.StackConfig(n_encoder_blocks=stack[4], n_decoder_blocks=stack[4]),\n",
        "              vd_vae.StackConfig(n_encoder_blocks=stack[3], n_decoder_blocks=stack[3]),\n",
        "              vd_vae.StackConfig(n_encoder_blocks=stack[2], n_decoder_blocks=stack[2]),\n",
        "              vd_vae.StackConfig(n_encoder_blocks=stack[1], n_decoder_blocks=stack[1]),\n",
        "              vd_vae.StackConfig(n_encoder_blocks=stack[0], n_decoder_blocks=stack[0]),\n",
        "            ]\n",
        "\n",
        "            print(stack_configs)\n",
        "\n",
        "          \n",
        "            model = vd_vae.VeryDeepVAE(\n",
        "                  in_channels=1,\n",
        "                  out_channels=1,\n",
        "                  input_resolution=ws,\n",
        "                  stack_configs=stack_configs,\n",
        "                  latent_channels=lc, #4  #set low since time series data less informative\n",
        "                  hidden_channels=hc, #16\n",
        "                  bottleneck_channels=bc, #8\n",
        "          )\n",
        "\n",
        "              # loss \n",
        "            optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "              #model trainer\n",
        "            model_trainer = pg.trainer.Trainer(\n",
        "                  model=model,\n",
        "                  loss_fn=loss_fn,\n",
        "                  optimizer=optimizer,\n",
        "                  train_loader=train,\n",
        "                  eval_loader=val,\n",
        "                  sample_epochs=1,\n",
        "                  sample_fn=sample_fn,\n",
        "                  log_dir=log_dir,\n",
        "                  n_gpus=n_gpus,\n",
        "                  device_id=device_id,\n",
        "                )\n",
        "              # save/ load model \n",
        "            model_trainer.interleaved_train_and_eval(n_epochs, restore=False)\n",
        "\n",
        "            #torch.save(model, f'/content/drive/My Drive/Master in Data Science and Society/Master Thesis/Code & Data Set/trained_models/VD_VAE_AMZN_GAF{str(ws)}_{str(sum(stack*2))}_{str((lc, hc, bc))}.h5')\n",
        "            #model = torch.load(f'/content/drive/My Drive/Master in Data Science and Society/Master Thesis/Code & Data Set/trained_models/VD_VAE_AMZN_GAF{str(ws)}_{str(sum(stack*2))}_{str(latent_channels)}.h5')\n",
        "\n",
        "              # evaluate \n",
        "            model_eval = model.train(False)\n",
        "\n",
        "            MSEs_of_inputs = []\n",
        "            for b in test: \n",
        "                        gc.collect()\n",
        "                        x = model_eval(b.cuda())\n",
        "                        x = x[0].detach()\n",
        "\n",
        "                        #MSE of inputs of batch\n",
        "                        sq_diff = torch.square(x - b.cuda())\n",
        "                        Batch_MSE = 0.5*torch.sum(sq_diff, [1,2,3])\n",
        "\n",
        "                        MSEs_of_inputs.append(Batch_MSE)\n",
        "                        gc.collect()\n",
        "\n",
        "              # convert to tensor \n",
        "            MSEs_of_inputs = torch.cat(MSEs_of_inputs)\n",
        "\n",
        "              # Threshold \n",
        "            std, mean = torch.std_mean(MSEs_of_inputs) # returns standard-deviation and mean\n",
        "\n",
        "            y_pred = []\n",
        "            for ind, r_error in enumerate(MSEs_of_inputs): \n",
        "                \n",
        "                # Anomaly detection\n",
        "                if r_error > (mean + 2*std) or r_error < (mean - 2*std):\n",
        "                      \n",
        "                    #print('Anomaly')\n",
        "                    #df['pred'][ind+(w-1)] = 1 #w is width set initially -1 due to Xue et al implementation\n",
        "                    y_pred.append(1)\n",
        "\n",
        "                else: \n",
        "                    #print('Normal')\n",
        "                    #df['pred'][ind+(w-1)] = 0\n",
        "                    y_pred.append(0)\n",
        "\n",
        "            y_true = df['label'][int((0.5*ws)-1):int(-0.5*ws)].tolist()\n",
        "\n",
        "            eval_score[f'VD_VAE_GAF{(lc, hc, bc, stack, lr, n_epochs)}'] = ( f1_score(y_true, y_pred),confusion_matrix(y_true, y_pred)) #assoiate with settings \n",
        "              \n",
        "\n",
        "            print(f'Dataset img size: {ws}')\n",
        "            print(f'lc:{lc}, hc{hc}, bc{bc}}')\n",
        "            print(f'config stack: {stack}, Layers:{sum(stack*2)}')\n",
        "            print(f'lr:{lr}')\n",
        "            print(f'ep:{n_epochs}')\n",
        "            print(f1_score(y_true, y_pred))\n",
        "            print(confusion_matrix(y_true, y_pred))\n",
        "            print(f'====')\n",
        "\n",
        "\n",
        "#check on best model different img size if time"
      ],
      "id": "cd8d2b77",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5uc_2vxRCEBw"
      },
      "source": [
        "# Benchmark\n",
        "# Dataset img size: 128\n",
        "# config stack: (1, 1, 1, 1, 1, 1), Layers:12\n",
        "# 0.5343228200371057\n",
        "\n",
        "# Last layer\n",
        "# config stack: (1, 2, 2, 2, 3, 3), Layers:26\n",
        "# 0.5343228200371057\n",
        "# config stack: (1, 2, 2, 3, 3, 4), Layers:30 == crash\n",
        "\n",
        "\n",
        "Dataset img size: 128\n",
        "lc:(4, 32, 8)\n",
        "config stack: (1, 1, 1, 1, 1, 1), Layers:12\n",
        "[StackConfig(n_encoder_blocks=1, n_decoder_blocks=1), StackConfig(n_encoder_blocks=1, n_decoder_blocks=1), StackConfig(n_encoder_blocks=1, n_decoder_blocks=1), StackConfig(n_encoder_blocks=1, n_decoder_blocks=1), StackConfig(n_encoder_blocks=1, n_decoder_blocks=1), StackConfig(n_encoder_blocks=1, n_decoder_blocks=1)]\n",
        "0.366412213740458"
      ],
      "id": "5uc_2vxRCEBw",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rUmj-28omduk"
      },
      "source": [
        "len( df['label'][int(((window_size)-1)):5000] ) "
      ],
      "id": "rUmj-28omduk",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QLLyWkdn3nt0"
      },
      "source": [
        "for k in [(1,1,1,1,1,1),(1,1,1,2,2,3),(1,1,2,2,2,3),(1,2,2,2,3,3),(1,2,2,3,3,4), (1,2,3,3,4,4), (1,2,3,4,4,5), (1,2,3,4,5,5)]: \n",
        "  print( sum(k*2) ) "
      ],
      "id": "QLLyWkdn3nt0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xgFTwUZdelFa"
      },
      "source": [
        "# Outtakes"
      ],
      "id": "xgFTwUZdelFa"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LUhYEDLT_O7F"
      },
      "source": [
        "# w = 0.5*window_size\n",
        "\n",
        "# # T2GAF Dataset \n",
        "# ts_windows = rolling_window(ts, window_size) #mulitple of window size \n",
        "\n",
        "# # Data preprocessing \n",
        "# ## Set up GAF \n",
        "# gasf = GramianAngularField(image_size=resolution, method='summation')# , sample_range=(0,1))\n",
        "\n",
        "# ## set up list storing img of ts window\n",
        "# ts_windows_img = []\n",
        "\n",
        "# for ts_window in ts_windows:\n",
        "\n",
        "#   ### GASF\n",
        "#   X_gasf = gasf.fit_transform(ts_window.reshape(1,-1))\n",
        "\n",
        "#   ts_windows_img.append(X_gasf[0])\n",
        "\n",
        "# # convert to tensor\n",
        "# tensor_img = torch.Tensor(ts_windows_img)\n",
        "\n",
        "# # Data loader set up \n",
        "# X_train, X_val, _, _ = train_test_split(tensor_img, \n",
        "#                                         tensor_img,\n",
        "#                                         test_size=0.1, \n",
        "#                                         random_state=42)\n",
        "\n",
        "# ## Dataset GAF\n",
        "# data_loader_train_GAF = torch.utils.data.DataLoader(preprocess_images(X_train),\n",
        "#                                           batch_size=batch_size ,\n",
        "#                                           shuffle=False)\n",
        "\n",
        "# data_loader_val_GAF = torch.utils.data.DataLoader(preprocess_images(X_val),\n",
        "#                                           batch_size=batch_size ,\n",
        "#                                           shuffle=False)\n",
        "\n",
        "# data_loader_test_GAF = torch.utils.data.DataLoader(preprocess_images(tensor_img),\n",
        "#                                           batch_size=batch_size ,\n",
        "#                                           shuffle=False)"
      ],
      "id": "LUhYEDLT_O7F",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qe9WJkYp-PDK"
      },
      "source": [
        "# # T2ALL\n",
        "# ts_windows = rolling_window(ts, w) #mulitple of window size \n",
        "# # Data preprocessing \n",
        "# gasf = GramianAngularField(image_size=w, method='summation')\n",
        "# gadf = GramianAngularField(image_size=w, method='difference')\n",
        "# rp = RecurrencePlot(dimension=1, time_delay=1, threshold='point', percentage=10)\n",
        "# mtf = MarkovTransitionField(image_size=w)\n",
        "\n",
        "# ## set up list storing img of ts window\n",
        "# ts_windows_img_all = []\n",
        "\n",
        "# for ts_window in ts_windows:\n",
        "\n",
        "#   ### GASF\n",
        "#   X_gasf = gasf.fit_transform(ts_window.reshape(1,-1))\n",
        "\n",
        "#   # ### GADF\n",
        "#   X_gadf = gadf.fit_transform(ts_window.reshape(1,-1))\n",
        "\n",
        "#   # ### RP\n",
        "#   X_rp = rp.fit_transform(ts_window.reshape(1,-1))\n",
        "\n",
        "#   # ### MTF \n",
        "#   X_mtf = mtf.fit_transform(ts_window.reshape(1,-1))\n",
        "\n",
        "#   # ### concat/ append\n",
        "#   x1 = np.concatenate((X_gadf[0], X_mtf[0]))\n",
        "#   x2 = np.concatenate((X_rp[0], X_gasf[0]))\n",
        "\n",
        "#   ts_windows_img_all.append(np.concatenate((x1,x2), 1))\n",
        "\n",
        "# # convert to tensor\n",
        "# tensor_img_all = torch.Tensor(ts_windows_img_all)\n",
        "\n",
        "# ## Train/ Validation data\n",
        "# X_train, X_val, _, _ = train_test_split(tensor_img_all, \n",
        "#                                         tensor_img_all,\n",
        "#                                         test_size=0.1, \n",
        "#                                         random_state=42)\n",
        "\n",
        "# ## Dataset all\n",
        "\n",
        "# data_loader_train_all = torch.utils.data.DataLoader(preprocess_images(X_train),\n",
        "#                                           batch_size=batch_size ,\n",
        "#                                           shuffle=False)\n",
        "\n",
        "# data_loader_val_all = torch.utils.data.DataLoader(preprocess_images(X_val),\n",
        "#                                           batch_size=batch_size ,\n",
        "#                                           shuffle=False)\n",
        "\n",
        "# data_loader_val_all = torch.utils.data.DataLoader(preprocess_images(tensor_img_all),\n",
        "#                                           batch_size=batch_size ,\n",
        "#                                           shuffle=False)"
      ],
      "id": "Qe9WJkYp-PDK",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LOD0abwDnbuk"
      },
      "source": [
        "# anomaly_err_score= [] #tuple with initial pred &  r_error\n",
        "\n",
        "# for ind, r_error in enumerate(MSEs_of_inputs): \n",
        "          \n",
        "#           # Anomaly detection\n",
        "#           if r_error > (mean + 2*std) or r_error < (mean - 2*std):\n",
        "                \n",
        "#               #print('Anomaly')\n",
        "#               #df['pred'][ind+(w-1)] = 1 #w is width set initially -1 due to Xue et al implementation\n",
        "#               anomaly_err_score.append(1, r_error)\n",
        "\n",
        "#           else: \n",
        "#               #print('Normal')\n",
        "#               #df['pred'][ind+(w-1)] = 0\n",
        "#               anomaly_err_score.append(0, r_error)\n",
        "\n",
        "import numpy as np \n",
        "y_pred = [0,1,1,0,0,0,0,1,1,1,1,0,0,1,1]\n",
        "MSEs_of_inputs = np.random.random(15)\n",
        "y_array = np.array(y_pred)\n",
        "ind_seq_1 = np.where(y_array==1)[0]\n",
        "\n"
      ],
      "id": "LOD0abwDnbuk",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U7xEUgSZ8tB4"
      },
      "source": [
        "def sub_sequence_anomalies(predictions): \n",
        "  \"\"\" \n",
        "  Function: \n",
        "  - Filters anomaly prediction sequences\n",
        "\n",
        "  Argument: \n",
        "  predictions = Takes list of prediction\n",
        "\n",
        "  Output: \n",
        "  - returns ind of anomalies \n",
        "  \"\"\"\n",
        "\n",
        "  sub_seq = []\n",
        "  l = []\n",
        "  for ind in range(len(predictions)): \n",
        "    \n",
        "    if predictions[ind]==0: \n",
        "      #normal\n",
        "      if l:  #check if list is empty and if not will append\n",
        "        sub_seq.append(l) # append anomaly seq\n",
        "        l=[] # reset\n",
        "\n",
        "      else: \n",
        "        continue\n",
        "        \n",
        "    elif predictions[ind]==1:\n",
        "      #append anomaly\n",
        "      l.append(ind)\n",
        "\n",
        "      #append subsequence if it end on anomaly\n",
        "      if ind == (len(predictions) - 1): \n",
        "        sub_seq.append(l)\n",
        "\n",
        "  return sub_seq\n",
        "\n",
        "sub_sequence_anomalies(y_pred)"
      ],
      "id": "U7xEUgSZ8tB4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZVLOmjoyDyUd"
      },
      "source": [
        "#filer out anomaly sequences \n",
        "sub_seq = sub_sequence_anomalies(y_pred)\n",
        "\n",
        "#get respective maximum of each sub_seq\n",
        "seq_max = []\n",
        "for ss in sub_seq: \n",
        "  \n",
        "  seq_max.append( np.max(MSEs_of_inputs[ss])) \n",
        "\n",
        "#sort in descending order \n",
        "seq_max_descent = np.sort(np.array(seq_max))[::-1]\n",
        "\n",
        "#std of all anomalies\n",
        "\n",
        "##std of anomalies  \n",
        "ind_seq_1 = np.where(np.array(y_pred)==1)[0] #filter ind position for all anomalies\n",
        "std_anomaly = np.std( MSEs_of_inputs[ind_seq_1]) \n",
        "\n",
        "\n",
        "# list of valid max values\n",
        "valid_max = []\n",
        "\n",
        "#artifically set max as first value of seqm_prev\n",
        "seqm_prev =  seq_max_descent[1]\n",
        "\n",
        "#iter \n",
        "for seqm in seq_max_descent[1:]:\n",
        "\n",
        "  if ( ((seqm_prev - seqm )/seqm) < 0.1) and (seqm < (4*std_anomaly)) and ( seqm < (0.95*np.max(seq_max_descent)) ): #criterion Xu et al. 2021\n",
        "    \n",
        "    valid_max.append(seqm) \n",
        "\n",
        "  seqm_prev = seqm\n",
        "\n",
        "valid_max.append(seqm) \n",
        "\n",
        "#correct anomalies \n",
        "y_pred_t = np.zeros(len(y_pred))\n",
        "\n",
        "for ind, max in enumerate(seq_max): #takes index and max value\n",
        "\n",
        "  if max in valid_max: #check if max in in valid max values \n",
        "\n",
        "    for k in sub_seq[ind]:  # takes sub-sequence list by index based on max value\n",
        "      \n",
        "      y_pred_t[k] = 1 #amend dummy y_pred\n",
        "\n",
        "y_pred_t\n",
        "\n",
        "\n"
      ],
      "id": "ZVLOmjoyDyUd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aRUV6ryqlkLM"
      },
      "source": [
        "y_pred"
      ],
      "id": "aRUV6ryqlkLM",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sl8wfnwZnrli"
      },
      "source": [
        "\n",
        "#sort in descending order\n",
        "#desent rate of sorted maximums 𝑝𝑖 = (𝑚𝑖−1 −𝑚𝑖 )/𝑚𝑖\n",
        "\n",
        "# if 𝑝𝑖 < 𝜃 & 𝑚𝑖 < 4 · 𝑠𝑡𝑑 &𝑚𝑖 < 𝜆 ·𝑚1 = true\n",
        "# thus (𝑚𝑖−1 −𝑚𝑖 )/𝑚𝑖 < 0.1 & 𝑚𝑖 < 4 · 𝑠𝑡𝑑 & 𝑚𝑖 < 0.95 · max = true\n",
        "#===> then subsequent sequences = normal \n",
        "\n",
        "\n",
        "## NOTE \n",
        "# copy setting of Xu et al. 2021\n",
        "# 𝜃 = 0.1, 𝜆 = 0.95, \n",
        "# 𝑠𝑡𝑑 refers to the standard eviation of anomaly scores on the whole ts"
      ],
      "id": "Sl8wfnwZnrli",
      "execution_count": null,
      "outputs": []
    }
  ]
}